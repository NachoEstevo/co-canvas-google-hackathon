import { NextRequest, NextResponse } from 'next/server'
import { GoogleGenAI } from '@google/genai'

const ai = new GoogleGenAI({
  apiKey: process.env.GEMINI_API_KEY!
})

// Helper function to build content array for Gemini
function buildGeminiContent(prompt: string, imageData?: string, images?: any[]) {
  const content: any[] = []
  
  // Always start with the text prompt
  content.push({ text: prompt })
  
  // Add main image data (sketch/drawing) if present
  if (imageData) {
    try {
      let base64Data = ''
      let mimeType = 'image/png'
      
      if (typeof imageData === 'string' && imageData.startsWith('data:image/')) {
        const matches = imageData.match(/^data:([^;]+);base64,(.+)$/)
        if (matches && matches[2]) {
          mimeType = matches[1]
          base64Data = matches[2]
        }
      }
      
      if (base64Data) {
        content.push({
          inlineData: {
            mimeType,
            data: base64Data
          }
        })
      }
    } catch (error) {
      console.error('Failed to process main image data:', error)
    }
  }
  
  // Add context images if present
  if (images && Array.isArray(images)) {
    for (const img of images) {
      if (img && img.data && typeof img.data === 'string') {
        try {
          content.push({
            inlineData: {
              mimeType: img.mimeType || 'image/png',
              data: img.data.trim()
            }
          })
        } catch (error) {
          console.warn('Failed to add context image:', error)
        }
      }
    }
  }
  
  return content
}

export async function POST(request: NextRequest) {
  try {
    const { prompt, imageData, images } = await request.json()

    if (!prompt) {
      return NextResponse.json({ error: 'Prompt is required' }, { status: 400 })
    }


    // Build the content array with prompt and images
    const content = buildGeminiContent(prompt, imageData, images)
    

    // Generate content using Gemini 2.5 Flash Image Preview
    const response = await ai.models.generateContent({
      model: "gemini-2.5-flash-image-preview",
      contents: content,
    })


    let generatedText = ''
    let generatedImageData = null
    let generatedImageUrl = null

    // Process response parts
    if (response.candidates && response.candidates[0] && response.candidates[0].content && response.candidates[0].content.parts) {
      for (const part of response.candidates[0].content.parts) {
        if (part.text) {
          generatedText += part.text
        } else if (part.inlineData && part.inlineData.data) {
          // This is the generated image!
          generatedImageData = part.inlineData.data
          generatedImageUrl = `data:${part.inlineData.mimeType || 'image/png'};base64,${part.inlineData.data}`
        }
      }
    } else {
      console.error('Invalid response structure from Gemini:', response)
    }

    if (!generatedImageUrl && !generatedText) {
      console.error('No content generated by Gemini. Full response:', JSON.stringify(response, null, 2))
      throw new Error('No content generated by Gemini')
    }

    return NextResponse.json({
      success: true,
      content: generatedText || 'Image generated successfully',
      imageUrl: generatedImageUrl,
      imageData: generatedImageUrl,
      analysis: generatedText,
      hasGeneratedImage: !!generatedImageUrl,
      note: 'Generated using Gemini 2.5 Flash Image Preview for actual image generation'
    })

  } catch (error) {
    console.error('Gemini image generation error:', error)
    return NextResponse.json(
      { 
        error: 'Failed to generate image', 
        details: error instanceof Error ? error.message : String(error),
        note: 'Error occurred while using Gemini 2.5 Flash Image Preview'
      },
      { status: 500 }
    )
  }
}